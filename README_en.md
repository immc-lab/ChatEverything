# ChatEverything

[[zh](https://github.com/immc-lab/ChatEverything/blob/main/README.md)] [[en](https://github.com/immc-lab/ChatEverything/blob/main/README_en.md)]
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re) <img src="https://img.shields.io/github/stars/immc-lab/fastbook-zh.svg"> <img src="https://img.shields.io/github/watchers/immc-lab/fastbook-zh.svg">

With the development of deep learning, large models continue to emerge. Large models can be models with a huge number of parameters in deep learning models. Recently, some work has effectively guided the knowledge of large models by combining the relevant foundation of reinforcement learning through the RLHF technique, allowing large models to achieve amazing results. However, there is currently a lack of systematic and logical integration of large model resources on the internet, which hinders the enthusiasm of many people to explore large model technology. Therefore, we have integrated the existing resources on the network to provide a clear and logical context.

If you find this repository helpful, please give us a ⭐ or share it ⬆️.

## News

```
2023.05.06 add
```

## 内容

-   [学术&产业](#学术&产业)
    -   [上游](#上游)
        -   [基座模型](#基座模型)
        -   [模型微调](#模型微调)
        -   [模型评估](#模型评估)
    -   [中游](#中游)
        -   [量化](#量化)
        -   [拓展](#拓展)
        -   [与其他模型的结合](#与其他模型的结合)
        -   [二次开发](#二次开发)
    -   [下游](#下游)
        -   [Web 应用](#Web应用)
        -   [小程序](#小程序)
        -   [聊天机器人](#聊天机器人)
-   [教程](#教程)
    -   [视频教程](#视频教程)
    -   [博客](#博客)
-   [资源](#资源)
    -   [工具](#工具)
    -   [免费 API](#免费API)
    -   [镜像网站](#镜像网站)

## 学术&产业

### 上游

#### 基座模型

##### textual

-   BELLE - https://github.com/LianjiaTech/BELLE
-   ChatGPT - https://chat.openai.com
-   Wenxin - https://yiyan.baidu.com/
-   ChatGLM - https://github.com/THUDM/ChatGLM-6B
-   Phoenix - https://github.com/FreedomIntelligence/LLMZoo
-   MiniGPT-4 - https://github.com/Vision-CAIR/MiniGPT-4
-   MOSS - https://github.com/OpenLMLab/MOSS

##### textual-vision

-   LLaVA

#### 模型微调

##### PHT-LoRA

-   Chinese-LLaMA-Alpaca - https://github.com/LC1332/Chinese-alpaca-lora
-   Yaya - https://github.com/qiyuan-chen/Yaya-Moss-Alpaca-LoRA

##### PHT-adapter

#### 模型评估

### 中游

#### 量化

-   llama.cpp - https://github.com/ggerganov/llama.cpp

#### 拓展

#### 与其他模型的结合

#### 二次开发

### 下游

#### Web 应用

#### 小程序

#### 聊天机器人

## 教程

### 视频教程

### 博客

## 资源

### 工具

-   peft - https://github.com/huggingface/peft

### 免费 API

-   GPTFree - https://github.com/xtekky/gpt4free

### 镜像网站

## Contributions

<p align="center"><a href="https://github.com/huaiwen"><img src="https://avatars.githubusercontent.com/u/3187529?v=4" width="50px" alt="robinicus" /></a>&nbsp;&nbsp;<a href="https://github.com/YangYang"><img src="https://avatars.githubusercontent.com/u/17808880?v=4" width="50px" alt="0xmatchmaker" /></a>&nbsp;&nbsp;<a href="https://github.com/guozihang"><img src="https://avatars.githubusercontent.com/u/17142416?v=4" width="50px" alt="0xmatchmaker" /></a>&nbsp;&nbsp;<a href="https://github.com/LeeRoc-China"><img src="https://avatars.githubusercontent.com/u/59104898?s=400&u=c225a082a6a410e3d7c84ca29a07d723d7308dca&v=4" width="50px" alt="0xmatchmaker" /></a>&nbsp;&nbsp;</p>
