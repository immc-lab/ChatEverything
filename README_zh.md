# 😎 **FollowGPT**

![ChatEveryThing](./images/Chat%20Everthing.png)

<img src="https://awesome.re/badge.svg"> <img src="https://img.shields.io/badge/lang-%E4%B8%AD%E6%96%87-red"> <img src="https://img.shields.io/badge/lang-En-red">

<img src="https://img.shields.io/github/stars/immc-lab/ChatEverything.svg"> <img src="https://img.shields.io/github/watchers/immc-lab/ChatEverything.svg">

---

人工智能的发展经历了从运算智能到感知智能，再到认知智能的三个阶段。运算智能关注机器的基础运算和存储能力，机器已经完胜人类。感知智能强调机器的模式识别能力，如语音和图像识别，目前机器在感知智能上的水平基本达到甚至超过了人类。然而，在涉及自然语言处理、常识建模和推理等研究的认知智能上，机器与人类还有很大差距。

人类语言（又称自然语言）具有无处不在的歧义性、高度抽象性、近乎无穷的语义组合性和持续进化性。理解语言需要具有一定的知识和推理等认知能力，这些都为计算机处理自然语言带来巨大挑战，使其成为机器难以逾越的鸿沟。因此，自然语言处理被认为是制约人工智能取得更大突破和更广泛应用的瓶颈之一，又被誉为**“人工智能皇冠上的明珠”**。

自然语言处理自诞生起，经历了五次研究范式转变。由最开始基于小规模专家知识的方法，逐步转向基于机器学习的方法。机器学习方法也由早期基于浅层机器学习模型变为基于深度学习模型。为解决深度学习模型需要大量标注数据问题，2018 年开始全面转向基于大规模预训练语言模型方法，其特点是充分利用**大模型、大数据**和**大计算**以求更好效果。

近期，ChatGPT 表现出非常惊艳的语言理解、生成、知识推理能力。它可以极好地理解用户意图，真正做到多轮沟通，并且回答内容完整、重点清晰、有概括、有逻辑、有条理。ChatGPT 的成功表现使人们看到了解决自然语言处理这一认知智能核心问题的一条可能路径，并被认为向通用人工智能迈出坚实一步。

当然，如此强大功能并不是一个简单模型能搞定。GPT 模型训练需要超大训练语料、超多模型参数以及超强计算资源。GPT 系列模型结构秉承不断堆叠 transformer 思想，并通过提升训练语料规模和质量、提升网络参数数量来完成 GPT 系列迭代更新。GPT 也证明通过提升模型容量和语料规模，模型能力可以不断提升。

|  模型   |   发布时间    | 参数量  | 预训练数据量 |
| :-----: | :-----------: | :-----: | :----------: |
|   GPT   | 2018 年 6 月  | 1.17 亿 |    约 5GB    |
|  GPT-2  | 2019 年 2 月  |  15 亿  |     40GB     |
|  GPT-3  | 2020 年 5 月  | 1750 亿 |     45TB     |
| chatGPT | 2022 年 11 月 |    -    |      -       |
|  GPT-4  | 2023 年 3 月  |    -    |      -       |

2018 年，OpenAI 提出了第一代 GPT（Generative Pretrained Transformer）模型。GPT-1 采用了 Transformer 架构和大规模无监督预训练方法，是一种自然语言生成模型。它在多个自然语言处理任务上表现出色，在单个英文句子的语言模型任务中达到了 SOTA 水平。GPT-1 的成功为基于预训练的自然语言处理模型的发展提供了新的思路和方法。

尽管 GPT-1 取得了巨大成功，但它并没有引起人们的关注。相反，谷歌随后提出的 BERT（Bidirectional Encoder Representations from Transformers）模型产生了更大的轰动。然而，OpenAI 继续沿着初代 GPT 的技术思路，陆续发布了 GPT-2 和 GPT-3 模型。

GPT-2 旨在训练一个泛化能力更强的词向量模型。它并没有对 GPT-1 的网络进行过多的结构创新与设计，只是使用了更多的网络参数和更大的数据集。GPT-2 最大的贡献是验证了通过海量数据和大量参数训练出来的词向量模型能够迁移到其他类别任务中而不需要额外的训练。但是，很多实验也表明，GPT-2 仍有很大提升空间。

GPT-3 仅需 zero-shot 或 few-shot 就能在下游任务中表现得非常好。除了几个常见的 NLP 任务外，GPT-3 还在很多困难任务上表现出惊艳能力，例如撰写人类难以判别的文章，甚至编写 SQL 查询语句、React 或 JavaScript 代码等。这些强大能力依赖于 GPT-3 拥有 1,750 亿超大规模参数，并且提出“提示语”（Prompt）概念。只要提供具体任务的提示语，即使不对模型进行调整也可完成该任务。

直到 ChatGPT 问世，才彻底改变了人们对于大模型的认知。它是基于 GPT-3.5 的，使用人类反馈强化学习技术，将人类偏好作为奖励信号并微调模型，实现有逻辑的对话能力。它的目标是生成有用、真实且无害的文本内容。然而，尽管 ChatGPT 在很多方面都表现出色，但它仍然存在一些局限性。例如，在深层次语义理解和生成上与人类认知水平还相去甚远。

GPT-4 是 OpenAI 在扩展深度学习方面的最新里程碑。它是一个大型多模态模型，能够接受图像和文本输入并发出文本输出。虽然在许多现实世界场景中的能力不如人类，但在各种专业和学术基准上表现出人类水平的表现。例如，它通过了模拟律师考试，分数约为考生的前 10%；相比之下，GPT-3.5 的得分约为倒数 10%。GPT-4 更具创造力和协作性。它能够生成、编辑和迭代用户进行创意和技术写作任务，例如创作歌曲、编写剧本或学习用户的写作风格。GPT-4 还能够接受图像作为输入，并生成字幕、分类和分析。此外，GPT-4 能够处理超过 25000 个单词的文本，允许使用长格式内容创建、扩展对话以及文档搜索和分析等用例。

虽然 GPT 目前已经取得了非常喜人的成果，但是未来仍然有诸多可以研究的方向。例如，当向机器提问时，关于上下文的背景知识是个普遍问题。举个例子来说，先让机器讲个笑话，又问它一个严肃的问题，人类可以从你的面部表情感受变化，知道现在已经不再是玩笑的语境，但是人工智能却还在继续那个笑话。这种语境感在交互中有着极大的作用。另外，在解决问题的难度方面，当我们做同一道数学方程式时，可能需要五、六次简化才能将其转化为正确形式，并且不断学习这些简化。而机器推理是通过层级线性下降推理链实现的，如果简化需要运行 10 次，机器可能就不会了。数学是非常抽象的推理，这是人工智能最大的弱点。无论是哪一个薄弱环节，都需要花时间才能解决，要严肃对待。我们需要更创新的模式，通过提示词（prompts）或训练对模型进行数学方面的训练。

现在，人工智能的新阶段才刚刚开始，我们正处于对它狂热的阶段，就像曾经对互联网的狂热一样。然而，目前互联网上缺乏系统的，有逻辑的大模型资源整合文档，阻碍了许多人探究大模型技术的热情，因此，我们对现有网络上的资源进行了整合，以提供一个清晰的富有逻辑的脉络。

如果您发现这个库对您有帮助的话，请点点您可爱小手给我们 ⭐ 或者 Sharing ⬆️

## 新闻 📰

```
2023.05.17 开始项目！
```

---

## GPT 汇总

#### 1.

#### 2.

#### 3.

使用预训练的大规模模型在下游任务上进行微调是当前流行的深度学习范式。尤其是近期预训练语言大模型 ChatGPT 的出色表现，使得这套技术范式得到了广泛的认可。我们主要了回答都有什么大模型的问题，站在一个宏观的角度为读者介绍了都有什么大模型，大模型覆盖了哪些范围。我们从自然语言处理，计算机视觉，多模态三个方面，搜集了从 2021 年到现在的相关论文。大模型在自然语言处理领域起步较早，然后逐步演化到计算机视觉相关领域，例如可以分割一切的 SAM。目前，将多个专业领域的大模型融合在一起成为了多模态领域大模型训练的新范式，例如华为推出的盘古大模型，其领域涵盖金融，气象等。我们的链接[Resources_3](./Resources/3)

#### 4.

#### 5.

---

## 详细教程

## 贡献者

<p align="center"><a href="https://github.com/huaiwen"><img src="https://avatars.githubusercontent.com/u/3187529?v=4" width="50px" alt="robinicus" /></a>&nbsp;&nbsp;<a href="https://github.com/YangYang"><img src="https://avatars.githubusercontent.com/u/17808880?v=4" width="50px" alt="0xmatchmaker" /></a>&nbsp;&nbsp;<a href="https://github.com/guozihang"><img src="https://avatars.githubusercontent.com/u/17142416?v=4" width="50px" alt="0xmatchmaker" /></a>&nbsp;&nbsp;<a href="https://github.com/LeeRoc-China"><img src="https://avatars.githubusercontent.com/u/59104898?s=400&u=c225a082a6a410e3d7c84ca29a07d723d7308dca&v=4" width="50px" alt="0xmatchmaker" /></a>&nbsp;&nbsp;</p>
